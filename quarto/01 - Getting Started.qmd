---
jupyter: python3
---

# Getting started

## Installation

See the [README](https://github.com/ibis-project/ibis-tutorial#setup) for
up-to-date installation instructions!

## Intro

We can begin by importing Ibis and firing up a connection to DuckDB! (DuckDB is
fast and runs locally, so it's handy for lots of use-cases, including
tutorials).

Here we connect to an existing DuckDB database containing a dataset on penguins.

```{python}
import ibis

con = ibis.duckdb.connect("data/penguins/palmer_penguins.ddb", read_only=True)
```

Now we have a connection, we can start by looking around.  Are there any tables
in this database (one would hope)?


```{python}
con.list_tables()
```

Yep, there's a table called `penguins`. Let's take a look at it.

```{python}
penguins = con.table("penguins")
```

By default, you'll get a `repr` showing the schema of the table, the column
names and the dtype of each column.

```{python}
penguins
```

If we run `head` to peek at the data, you'll notice that we don't actually see
data (yet), what's going on?

```{python}
penguins.head()
```

Ibis has a deferred execution model.  It builds up expressions based on what you
ask it to do, and then executes those expressions on request.

In this case, our query isn't too involved, we want to see the first few rows of
the `penguins` table.

We can do that by asking for the results of this query as a `pandas.DataFrame`:

```{python}
penguins.head().to_pandas()
```

Or a `pyarrow.Table`:

```{python}
penguins.head().to_pyarrow()
```

Or a `polars.DataFrame`:

```{python}
penguins.head().to_polars()
```

We'll get into more detail about what Ibis is doing a bit later on.  For now,
the important point is that Ibis is deferred.

## Interactive Mode

Remember when we said Ibis is deferred? Sometimes you want eager execution so
you can explore a dataset.  For most of this tutorial, we'll turn on
`interactive` mode, where Ibis will eagerly execute as much of the query as it
needs to in order to show you the first 10 rows of the result.

```{python}
ibis.options.interactive = True
```

In interactive mode, we use `rich` to render the output inline:

```{python}
penguins.head()
```

## Tables and Columns

`penguins` is a table!  A table is a collection of one or more columns, each
with a specific datatype.

```{python}
penguins.head()
```

```{python}
type(penguins)
```

We can look at a single column of that table using the column name as an
attribute:

```{python}
penguins.species
```

What kind of column is `species`? It's a `StringColumn`!

```{python}
type(penguins.species)
```

## Ibis "verbs", or, stuff you can do to a table

The rest of this notebook covers some of the general methods you can use to
alter the output of a particular table.

We'll cover, in order, `filter`, `select`, `drop`, `mutate`, `order_by`,
`aggregate`, `group_by`, and `join`. Time to dive in!

## Filter

A filter allows you to view a subset of the rows in a table, based on some condition.

For instance, we might want to only view penguin data for the Adelie species:

```{python}
penguins.filter(penguins.species == "Adelie")
```

You can also combine multiple filters, across multiple columns.

We can subset the data down to Adelie penguins residing on the island of Dream:

```{python}
expr = penguins.filter(
    (penguins.island == "Dream") & (penguins.species == "Adelie")
)

expr
```

Above we combined two filters using `&`, you can also pass them in as
individual arguments:

```{python}
expr = penguins.filter(
        penguins.island == "Dream",
        penguins.species == "Adelie",
)
expr
```

```{python}
ibis.to_sql(expr)
```

## Select

Filter filters, Select selects (there's a pattern here). If you only want a
subset of the columns in the original table, you can select those columns
explicitly.

You can refer to the columns using strings:

```{python}
penguins.select("species", "island", "year")
```

Or you can use explicit references to the `Column` objects:

```{python}
penguins.select(penguins.species, penguins.island, penguins.year)
```

Or you can mix and match:

```{python}
penguins.select("species", "island", penguins.year)
```

## Drop

Drop is nearly the same as Select, but rather than explicitly choosing the
columns to display, we explicitly choose the columns to _not_ display.

And as with `select`, you can specify the columns as strings:

```{python}
penguins.drop("sex", "year")
```

Or you can use explicit references to the `Column` objects:

```{python}
penguins.drop(penguins.sex, penguins.year)
```

Or you can mix and match:

```{python}
penguins.drop("sex", penguins.year)
```

## Mutate

Everything we've seen so far has been subtractive -- removing rows or columns.
What about _adding_ columns?

That's what `mutate` is for! You can create a new column -- either as a
function of other existing columns (for example, converting units):

```{python}
penguins.mutate(bill_length_cm=penguins.bill_length_mm / 10)
```

Or you can create a new column and populate it with some literal value:

```{python}
penguins.mutate(my_favorite_number=ibis.literal(41))
```

## On immutability

We've filtered, selected, dropped, and mutated this `penguins` table quite a bit.

```{python}
penguins
```

And yet, notice that none of our changes persist -- the base table for our
query isn't altered. The query (or expression) is a recipe of things to do with
the base table (`penguins`).

If you want to keep an expression around, you can assign it to a variable:

```{python}
expr = penguins.select("species", "island")
expr
```

**Note**: Every time you execute an expression (via interactive mode, or
  `to_pandas`, or similar), the entire expression gets executed, starting from
  the base table.  DuckDB is very fast and this dataset is very small, so the
  delay is unnoticeable, but for very large datasets, it might become more
  pronounced.  There is functionality to `cache` intermediate results that isn't
  covered in this tutorial, but you can read more about it in [the
  docs](https://ibis-project.org/reference/expression-tables.html#ibis.expr.types.relations.Table.cache).

## Method chaining

You can build up complicated queries by chaining together Ibis methods. The
output of many Ibis methods is a table (just like `penguins`!) and we can
continue calling table methods until we're satisfied.  Or until we end up with
something that _isn't_ a table.  More on that later.

```{python}
penguins.select("species", "island", "year", "bill_length_mm").drop("year")
```

Not the most staggeringly complicated query, but we'll see more soon.

### Exercise 1

Your PI is a cranky American biologist who thinks the metric system is for
suckers (oh no).

They demand that we convert all of the existing measurements (`mm` and `g`) to
inches and lbs, respectively (I am so sorry). The PI is extra cranky this
morning, so we had better make sure that ONLY the silly units are visible in
the output.

Some ~helpful~ cursed conversion factors:

|  |  |
| -- | -- |
| mm -> in | divide by 25.4 |
| g -> lb | divide by 453.6 |

Two ways you might accomplish this:
- Chaining `.mutate` to create new columns and `.drop` to drop the old metric columns
- Using a single `.select` to create the new columns as well as select the relevant older columns

Try both ways below! How do they compare?

```{python}
# Convert the metric units to imperial, and drop the metric columns.
# Try this using a `.mutate` and `.drop` call.
penguins_imperial_mutate_drop = penguins
```

```{python}
# Convert the metric units to imperial, and drop the metric columns.
# Try this using a single `.select` call.
penguins_imperial_select = penguins
```

#### Solutions

```{python}
%load solutions/nb01_ex01_mutate_drop.py
```

```{python}
%load solutions/nb01_ex01_select.py
```

### Does it matter which method you choose?

In this case, no.  Sometimes, there might be a small difference in the generated
SQL but they will be semantically equivalent..

```{python}
ibis.to_sql(penguins_imperial_mutate_drop)
```

```{python}
ibis.to_sql(penguins_imperial_select)
```

In practice, small differences in the generated SQL don't make a difference.
Any modern SQL execution engine will optimize variations to the same set of
operations and there will be no measurable performance difference.

## Order By

Want to order your data by a given column or columns?  Use `order_by`!

The default ordering direction is ascending:

```{python}
penguins.order_by(penguins.flipper_length_mm)
```

We can ask Ibis to sort in descending order, too.

```{python}
penguins.order_by(penguins.flipper_length_mm.desc())
```

Let's select out a subset of the columns to keep this a bit tidier.

```{python}
penguins.order_by(penguins.flipper_length_mm.desc()).select(
    "species", "island", "flipper_length_mm"
)
```

You can also call `ibis.desc` on the column name to set the order direction:

```{python}
(
    penguins
    .order_by(ibis.desc("flipper_length_mm"))
    .select("species", "island", "flipper_length_mm")
)
```

## Aggregate

Ibis has several aggregate functions available to help summarize data.  All the
old favorites are there: `mean`, `max`, `min`, `count`, `sum`...

You can aggregate a column by calling the method on that column:

```{python}
penguins.flipper_length_mm.mean()
```

Or you can compute multiple aggregates using the `aggregate` method (also
available as `agg` for faster typing):

```{python}
penguins.agg(
    [
        penguins.flipper_length_mm.mean(),
        penguins.bill_depth_mm.max()
    ]
)
```

But aggregates really shine when paired with a `group_by`!

## Group By

`group_by` creates groupings of rows that have the same value for one or more columns.

But it doesn't do much on its own -- you can pair it with aggregate to get a result.

```{python}
penguins.group_by("species").agg()
```

Without any `aggregate` function specified, we get the distinct values of the
grouped-column.

We can add a second column to the `group_by` to get the distinct pairs across
both columns:

```{python}
penguins.group_by(["species", "island"]).agg()
```

Now, if we add an aggregation function to that, we start to really open things up.

```{python}
penguins.group_by(["species", "island"]).agg(penguins.bill_length_mm.mean())
```

By adding that `mean` to the `aggregate`, we now have a concise way to calculate
aggregates over each of the distinct groups in the `group_by`. And we can
calculate as many aggregates as we need.

```{python}
penguins.group_by(["species", "island"]).agg(
    [penguins.bill_length_mm.mean(), penguins.flipper_length_mm.max()]
)
```

If we need more specific groups, we can add to the `group_by`.

```{python}
penguins.group_by(["species", "island", "sex"]).agg(
        [penguins.bill_length_mm.mean(), penguins.flipper_length_mm.max()]
    )
```

## Exercises

Time to use what we've learned to answer some penguin questions.

### Exercise 2

What was the largest female penguin (by body mass) on each island in the year 2008?


#### Solution

Note that there are several ways these queries could be written - it's fine if
your solution doesn't look like ours, what's important is that the results are
the same.

```{python}
%load solutions/nb01_ex02.py
```

### Exercise 3

What was the largest male penguin (by body mass) on each island for each year of
data collection?


#### Solution

```{python}
%load solutions/nb01_ex03.py
```

## Join

So far all the methods we've introduced work on a single Table. Some queries require
information contained in *multiple* tables. This is where `join` comes in!

Joins describe how to combine multiple tables into a single table by
correlating rows found in the "left" and "right" tables in the join.

There are many different kinds of join (left, right, inner, outer, semi, anti,
...). The simplest is the "inner join" on a single column. Barring a treatise
on joins, you may think of an inner join as a way to add extra columns from a
`right` table to the `left` table via a lookup column. In ibis this join is
invoked like:

```python
left.join(right, ("key_column_name_in_left", "key_column_name_in_right"))

# OR if the column names are the same in both
left.join(right, "key_column_name")
```

### Exercise 4

Add a new column to the `penguins` table with the mean mass of penguins found
on that island.

```{python}
mean_mass_per_island = (
    penguins
    .group_by("island")
    .agg(island_mean_mass=penguins.body_mass_g.mean())
)

penguins.join(...)  # what goes here?
```

#### Solution

```{python}
%load solutions/nb01_ex04.py
```

## Ibis's magical `_` ("Deferred") API

Ibis's query API is optimized to be able to build up complex queries through
method chaining. For example, in the above query we chain a `group_by`, `agg`
and `join` call together into a single larger query.

Sometimes we want to be able to refer to the output of one method in a later
method call. One way to make calls like this more concise is to make use of
ibis's `_` API. This is a "magical" object that constructs "deferred
expressions". Everywhere you see `_` in the expression you should read "the
current table (`self`) in the method being called".

For example, both of these calls do the same thing:

```{python}
from ibis import _
```

```{python}
# Explicitly referencing `penguins.bill_length_mm` and `penguins.bill_depth_mm`
t1 = penguins.mutate(
    length_depth_ratio=penguins.bill_length_mm / penguins.bill_depth_mm
)

t1
```

```{python}
# Using deferred expressions (the `_` object)
t2 = penguins.mutate(
    length_depth_ratio=_.bill_length_mm / _.bill_depth_mm
)

t2
```

We can even check that they're the same by asserting that the expressions
backing each `ibis.Table` are identical (remember, `ibis` uses a lazy
expression API behind the scenes):

```{python}
assert t1.equals(t2)  # assert the expressions backing t1 and t2 are equivalent
```

## A brief digression on the SQL Ibis generates

Maybe you've heard that SQL has a standard?  This is true, and also misleading.
The SQL standard is more of a suggestion, and there are myriad SQL _dialects_.

Ibis compiles expressions into the appropriate SQL dialect for the backend you
are using. In this case, we started with a DuckDB table, so we get DuckDB SQL:

```{python}
ibis.to_sql(expr)
```

But if you want to use a _different_ dialect, you can pass the dialect name:

```{python}
ibis.to_sql(expr, dialect="postgres")
```

## Explore Ibis's API

Ibis has _many_ methods on its `Table` and various `Column` types, we've only
covered a few so far. Besides our [API
docs](https://ibis-project.org/reference/expression-tables), another good way of
exploring the API is through `<TAB>` completion in your notebook or terminal
session. Doing

```python
# Explore the Table API
penguins.<TAB>
```

or 

```python
# Explore the Column API
penguins.species.<TAB>
# or for a different column type
penguins.body_mass_g.<TAB>
```

can help you learn what other methods Ibis has to offer.


### Exercise 5

Find and read the docstring on `ibis.Column.cast`. Then try to cast
`penguins.year` to `"float64"`, `"string"`, `"date"`, and `"int8"`. happens for
each type and why?

```{python}
# Your code here ...
```

### Exercise 6

Find one interesting method on a Table or Column type that we didn't talk about
here. Read through the docstring and example, and try calling it on the
`penguins` dataset. If you're in need of a suggestion, you might try looking at
`Table.rename`, `Table.fillna`, `Table.dropna`, or `Table.describe`, but we
suggest exploring around through tab-completion yourself too.

```{python}
# Your code here ...
```

### References

1: Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago
(Antarctica) penguin data. R package version 0.1.0.
https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.
